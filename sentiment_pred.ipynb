{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Sentiment Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df = pd.read_csv('data/yelp_revs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jess S.</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Everything from the atmosphere to the service ...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlene B.</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>4</td>\n",
       "      <td>You dont have to be vegan to appreciate the fo...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poonam M.</td>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>4</td>\n",
       "      <td>This the old Juniper so the layout is the same...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzan L.</td>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>Very disappointing experience The Sakura cockt...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sangeetha M.</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>4</td>\n",
       "      <td>I ordered for delivery so I cant comment on th...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author datePublished  reviewRating  \\\n",
       "0       Jess S.    2021-07-05             5   \n",
       "1     Arlene B.    2021-10-03             4   \n",
       "2     Poonam M.    2021-08-08             4   \n",
       "3      Suzan L.    2021-06-26             1   \n",
       "4  Sangeetha M.    2021-05-05             4   \n",
       "\n",
       "                                         description              name  \n",
       "0  Everything from the atmosphere to the service ...  MILA Plant-Based  \n",
       "1  You dont have to be vegan to appreciate the fo...  MILA Plant-Based  \n",
       "2  This the old Juniper so the layout is the same...  MILA Plant-Based  \n",
       "3  Very disappointing experience The Sakura cockt...  MILA Plant-Based  \n",
       "4  I ordered for delivery so I cant comment on th...  MILA Plant-Based  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing binary sentiment prediction, we need to place the numerical ratings into two categories: 'good' and 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(rating):\n",
    "    if rating > 3:\n",
    "        return 'good'\n",
    "    else:\n",
    "        return 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>reviewSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jess S.</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Everything from the atmosphere to the service ...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlene B.</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>4</td>\n",
       "      <td>You dont have to be vegan to appreciate the fo...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poonam M.</td>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>4</td>\n",
       "      <td>This the old Juniper so the layout is the same...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzan L.</td>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>Very disappointing experience The Sakura cockt...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sangeetha M.</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>4</td>\n",
       "      <td>I ordered for delivery so I cant comment on th...</td>\n",
       "      <td>MILA Plant-Based</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author datePublished  reviewRating  \\\n",
       "0       Jess S.    2021-07-05             5   \n",
       "1     Arlene B.    2021-10-03             4   \n",
       "2     Poonam M.    2021-08-08             4   \n",
       "3      Suzan L.    2021-06-26             1   \n",
       "4  Sangeetha M.    2021-05-05             4   \n",
       "\n",
       "                                         description              name  \\\n",
       "0  Everything from the atmosphere to the service ...  MILA Plant-Based   \n",
       "1  You dont have to be vegan to appreciate the fo...  MILA Plant-Based   \n",
       "2  This the old Juniper so the layout is the same...  MILA Plant-Based   \n",
       "3  Very disappointing experience The Sakura cockt...  MILA Plant-Based   \n",
       "4  I ordered for delivery so I cant comment on th...  MILA Plant-Based   \n",
       "\n",
       "  reviewSentiment  \n",
       "0            good  \n",
       "1            good  \n",
       "2            good  \n",
       "3             bad  \n",
       "4            good  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['reviewSentiment'] = yelp_df['reviewRating'].apply(sentiment)\n",
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    471\n",
       "bad     115\n",
       "Name: reviewSentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['reviewSentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalance in class distribution so we will need to address that during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(yelp_df['description'], yelp_df['reviewSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "#train_good = yelp_df.query('reviewSentiment == \"good\"')\n",
    "#train_bad = yelp_df.query('reviewSentiment == \"bad\"')\n",
    "\n",
    "#good_profile = ProfileReport(train_good, title=\"Pandas Profiling Report\")\n",
    "#good_profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Autograding\n",
    "#import tests_lab4\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_cross_val_results(model_name, scores, results_dict):\n",
    "    \"\"\"\n",
    "    Stores mean scores from cross_validate in results_dict for\n",
    "    the given model model_name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name :\n",
    "        scikit-learn classification model\n",
    "    scores : dict\n",
    "        object return by `cross_validate`\n",
    "    results_dict: dict\n",
    "        dictionary to store results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    results_dict[model_name] = {\n",
    "        \"mean_train_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"train_score\"])),\n",
    "        \"mean_valid_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"test_score\"])),\n",
    "        \"mean_fit_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"fit_time\"])),\n",
    "        \"mean_score_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"score_time\"])),\n",
    "        \"std_train_score\": \"{:0.4f}\".format(scores[\"train_score\"].std()),\n",
    "        \"std_valid_score\": \"{:0.4f}\".format(scores[\"test_score\"].std()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time (s) mean_score_time (s) mean_train_accuracy  \\\n",
       "Dummy            0.0020              0.0014              0.6657   \n",
       "\n",
       "      mean_valid_accuracy std_train_score std_valid_score  \n",
       "Dummy              0.6969          0.0097          0.0402  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "dummy = DummyClassifier()\n",
    "scores = cross_validate(dummy, X_train, y_train, n_jobs=-1, return_train_score=True)\n",
    "store_cross_val_results(\"Dummy\", scores, results_dict)\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.1536</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean_train_accuracy mean_valid_accuracy mean_fit_time (s)  \\\n",
       "Dummy                            0.6657              0.6969            0.0020   \n",
       "Decision Tree                    1.0000              0.7608            0.0990   \n",
       "RBF SVM                          0.9516              0.8157            0.1536   \n",
       "Naive Bayes                      0.9789              0.8543            0.0552   \n",
       "Logistic Regression              1.0000              0.8634            0.1552   \n",
       "\n",
       "                    mean_score_time (s) std_train_score std_valid_score  \n",
       "Dummy                            0.0014          0.0097          0.0402  \n",
       "Decision Tree                    0.0154          0.0000          0.0439  \n",
       "RBF SVM                          0.0332          0.0072          0.0596  \n",
       "Naive Bayes                      0.0098          0.0043          0.0206  \n",
       "Logistic Regression              0.0094          0.0000          0.0200  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"RBF SVM\": SVC(class_weight='balanced'),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, class_weight='balanced'),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipe = make_pipeline(CountVectorizer(), model)\n",
    "    scores = cross_validate(pipe, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "    store_cross_val_results(model_name, scores, results_dict)\n",
    "\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  4619\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "pipe.fit(X_train, y_train)\n",
    "vocab_size = len(pipe[\"countvectorizer\"].get_feature_names())  # get the vocab_size for\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import lognorm, loguniform, randint\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": loguniform(1e-3, 1e3),\n",
    "    \"countvectorizer__max_features\": randint(100, vocab_size),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 235 out of 250 | elapsed:    6.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(class_weight='balanced',\n",
       "                                                                 max_iter=1000))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'countvectorizer__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000208427DF640>,\n",
       "                                        'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000208427DF520>},\n",
       "                   random_state=123, return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    n_iter=50,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values:  {'countvectorizer__max_features': 1042, 'logisticregression__C': 5.806334557802442}\n",
      "Best score: 0.868\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867973</td>\n",
       "      <td>5.80633</td>\n",
       "      <td>1042</td>\n",
       "      <td>0.131202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>18.9554</td>\n",
       "      <td>3682</td>\n",
       "      <td>0.229753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>10.3725</td>\n",
       "      <td>3787</td>\n",
       "      <td>0.184199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>14.7411</td>\n",
       "      <td>3425</td>\n",
       "      <td>0.157998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>12.577</td>\n",
       "      <td>3416</td>\n",
       "      <td>0.179399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865700</td>\n",
       "      <td>326.844</td>\n",
       "      <td>967</td>\n",
       "      <td>0.153405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865674</td>\n",
       "      <td>4.15299</td>\n",
       "      <td>3637</td>\n",
       "      <td>0.168004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865648</td>\n",
       "      <td>0.42799</td>\n",
       "      <td>3581</td>\n",
       "      <td>0.132601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865648</td>\n",
       "      <td>0.358907</td>\n",
       "      <td>3962</td>\n",
       "      <td>0.144812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863401</td>\n",
       "      <td>18.5503</td>\n",
       "      <td>4033</td>\n",
       "      <td>0.193421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863401</td>\n",
       "      <td>1.51486</td>\n",
       "      <td>3164</td>\n",
       "      <td>0.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863401</td>\n",
       "      <td>39.4435</td>\n",
       "      <td>1804</td>\n",
       "      <td>0.140598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863401</td>\n",
       "      <td>1.0257</td>\n",
       "      <td>3352</td>\n",
       "      <td>0.178029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.317785</td>\n",
       "      <td>2111</td>\n",
       "      <td>0.120199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861102</td>\n",
       "      <td>0.225271</td>\n",
       "      <td>4243</td>\n",
       "      <td>0.134199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>205.098</td>\n",
       "      <td>4129</td>\n",
       "      <td>0.200827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>105.273</td>\n",
       "      <td>4199</td>\n",
       "      <td>0.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861076</td>\n",
       "      <td>229.264</td>\n",
       "      <td>4607</td>\n",
       "      <td>0.205021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858882</td>\n",
       "      <td>1.30891</td>\n",
       "      <td>795</td>\n",
       "      <td>0.111996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>2.11982</td>\n",
       "      <td>1543</td>\n",
       "      <td>0.141013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>32.3041</td>\n",
       "      <td>2104</td>\n",
       "      <td>0.150402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.998862</td>\n",
       "      <td>0.858830</td>\n",
       "      <td>0.191007</td>\n",
       "      <td>2096</td>\n",
       "      <td>0.119801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>766.629</td>\n",
       "      <td>1693</td>\n",
       "      <td>0.135599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.992597</td>\n",
       "      <td>0.858804</td>\n",
       "      <td>0.0723271</td>\n",
       "      <td>4212</td>\n",
       "      <td>0.134017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.998862</td>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.400135</td>\n",
       "      <td>937</td>\n",
       "      <td>0.114402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.174908</td>\n",
       "      <td>3802</td>\n",
       "      <td>0.128401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>2528</td>\n",
       "      <td>0.124036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856531</td>\n",
       "      <td>6.17664</td>\n",
       "      <td>1192</td>\n",
       "      <td>0.131802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.992597</td>\n",
       "      <td>0.856531</td>\n",
       "      <td>0.0817709</td>\n",
       "      <td>3581</td>\n",
       "      <td>0.134407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854284</td>\n",
       "      <td>2.72108</td>\n",
       "      <td>538</td>\n",
       "      <td>0.132820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>0.939617</td>\n",
       "      <td>655</td>\n",
       "      <td>0.122206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852038</td>\n",
       "      <td>1.55226</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.144276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852011</td>\n",
       "      <td>22.2194</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.156055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849765</td>\n",
       "      <td>2.57386</td>\n",
       "      <td>471</td>\n",
       "      <td>0.144620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.993737</td>\n",
       "      <td>0.849713</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>1079</td>\n",
       "      <td>0.108406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.847440</td>\n",
       "      <td>0.086647</td>\n",
       "      <td>1482</td>\n",
       "      <td>0.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.987471</td>\n",
       "      <td>0.845167</td>\n",
       "      <td>0.0775887</td>\n",
       "      <td>1211</td>\n",
       "      <td>0.111214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.981774</td>\n",
       "      <td>0.845167</td>\n",
       "      <td>0.0404411</td>\n",
       "      <td>4335</td>\n",
       "      <td>0.121806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.987471</td>\n",
       "      <td>0.845141</td>\n",
       "      <td>0.0578475</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.109799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.973236</td>\n",
       "      <td>0.826959</td>\n",
       "      <td>0.0801148</td>\n",
       "      <td>490</td>\n",
       "      <td>0.101001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.960703</td>\n",
       "      <td>0.826933</td>\n",
       "      <td>0.0318223</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.100802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826907</td>\n",
       "      <td>38.2843</td>\n",
       "      <td>371</td>\n",
       "      <td>0.150997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.951591</td>\n",
       "      <td>0.817868</td>\n",
       "      <td>0.0229672</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.114610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.935651</td>\n",
       "      <td>0.813297</td>\n",
       "      <td>0.0120786</td>\n",
       "      <td>3037</td>\n",
       "      <td>0.102022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.924257</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>1542</td>\n",
       "      <td>0.096001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.906603</td>\n",
       "      <td>0.806505</td>\n",
       "      <td>0.00898996</td>\n",
       "      <td>1233</td>\n",
       "      <td>0.095207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.997722</td>\n",
       "      <td>0.783542</td>\n",
       "      <td>3.00722</td>\n",
       "      <td>196</td>\n",
       "      <td>0.130598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.863894</td>\n",
       "      <td>0.781452</td>\n",
       "      <td>0.0031795</td>\n",
       "      <td>2150</td>\n",
       "      <td>0.095229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.826871</td>\n",
       "      <td>0.747257</td>\n",
       "      <td>0.00124961</td>\n",
       "      <td>2341</td>\n",
       "      <td>0.093795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.811496</td>\n",
       "      <td>0.740465</td>\n",
       "      <td>0.0018262</td>\n",
       "      <td>421</td>\n",
       "      <td>0.090798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_train_score  mean_test_score  \\\n",
       "rank_test_score                                      \n",
       "1                        1.000000         0.867973   \n",
       "2                        1.000000         0.867947   \n",
       "2                        1.000000         0.867947   \n",
       "2                        1.000000         0.867947   \n",
       "2                        1.000000         0.867947   \n",
       "6                        1.000000         0.865700   \n",
       "7                        1.000000         0.865674   \n",
       "8                        1.000000         0.865648   \n",
       "8                        1.000000         0.865648   \n",
       "10                       1.000000         0.863401   \n",
       "11                       1.000000         0.863401   \n",
       "11                       1.000000         0.863401   \n",
       "11                       1.000000         0.863401   \n",
       "14                       1.000000         0.863375   \n",
       "15                       1.000000         0.861102   \n",
       "16                       1.000000         0.861076   \n",
       "16                       1.000000         0.861076   \n",
       "16                       1.000000         0.861076   \n",
       "19                       1.000000         0.858882   \n",
       "20                       1.000000         0.858856   \n",
       "20                       1.000000         0.858856   \n",
       "22                       0.998862         0.858830   \n",
       "23                       1.000000         0.858804   \n",
       "24                       0.992597         0.858804   \n",
       "25                       0.998862         0.856557   \n",
       "25                       0.999430         0.856557   \n",
       "25                       0.996584         0.856557   \n",
       "28                       1.000000         0.856531   \n",
       "28                       0.992597         0.856531   \n",
       "30                       1.000000         0.854284   \n",
       "31                       1.000000         0.852038   \n",
       "31                       1.000000         0.852038   \n",
       "33                       1.000000         0.852011   \n",
       "34                       1.000000         0.849765   \n",
       "35                       0.993737         0.849713   \n",
       "36                       0.990318         0.847440   \n",
       "37                       0.987471         0.845167   \n",
       "38                       0.981774         0.845167   \n",
       "39                       0.987471         0.845141   \n",
       "40                       0.973236         0.826959   \n",
       "41                       0.960703         0.826933   \n",
       "42                       1.000000         0.826907   \n",
       "43                       0.951591         0.817868   \n",
       "44                       0.935651         0.813297   \n",
       "45                       0.924257         0.811024   \n",
       "46                       0.906603         0.806505   \n",
       "47                       0.997722         0.783542   \n",
       "48                       0.863894         0.781452   \n",
       "49                       0.826871         0.747257   \n",
       "50                       0.811496         0.740465   \n",
       "\n",
       "                param_logisticregression__C  \\\n",
       "rank_test_score                               \n",
       "1                                   5.80633   \n",
       "2                                   18.9554   \n",
       "2                                   10.3725   \n",
       "2                                   14.7411   \n",
       "2                                    12.577   \n",
       "6                                   326.844   \n",
       "7                                   4.15299   \n",
       "8                                   0.42799   \n",
       "8                                  0.358907   \n",
       "10                                  18.5503   \n",
       "11                                  1.51486   \n",
       "11                                  39.4435   \n",
       "11                                   1.0257   \n",
       "14                                 0.317785   \n",
       "15                                 0.225271   \n",
       "16                                  205.098   \n",
       "16                                  105.273   \n",
       "16                                  229.264   \n",
       "19                                  1.30891   \n",
       "20                                  2.11982   \n",
       "20                                  32.3041   \n",
       "22                                 0.191007   \n",
       "23                                  766.629   \n",
       "24                                0.0723271   \n",
       "25                                 0.400135   \n",
       "25                                 0.174908   \n",
       "25                                 0.140079   \n",
       "28                                  6.17664   \n",
       "28                                0.0817709   \n",
       "30                                  2.72108   \n",
       "31                                 0.939617   \n",
       "31                                  1.55226   \n",
       "33                                  22.2194   \n",
       "34                                  2.57386   \n",
       "35                                 0.150877   \n",
       "36                                 0.086647   \n",
       "37                                0.0775887   \n",
       "38                                0.0404411   \n",
       "39                                0.0578475   \n",
       "40                                0.0801148   \n",
       "41                                0.0318223   \n",
       "42                                  38.2843   \n",
       "43                                0.0229672   \n",
       "44                                0.0120786   \n",
       "45                                 0.011052   \n",
       "46                               0.00898996   \n",
       "47                                  3.00722   \n",
       "48                                0.0031795   \n",
       "49                               0.00124961   \n",
       "50                                0.0018262   \n",
       "\n",
       "                param_countvectorizer__max_features  mean_fit_time  \n",
       "rank_test_score                                                     \n",
       "1                                              1042       0.131202  \n",
       "2                                              3682       0.229753  \n",
       "2                                              3787       0.184199  \n",
       "2                                              3425       0.157998  \n",
       "2                                              3416       0.179399  \n",
       "6                                               967       0.153405  \n",
       "7                                              3637       0.168004  \n",
       "8                                              3581       0.132601  \n",
       "8                                              3962       0.144812  \n",
       "10                                             4033       0.193421  \n",
       "11                                             3164       0.168200  \n",
       "11                                             1804       0.140598  \n",
       "11                                             3352       0.178029  \n",
       "14                                             2111       0.120199  \n",
       "15                                             4243       0.134199  \n",
       "16                                             4129       0.200827  \n",
       "16                                             4199       0.201600  \n",
       "16                                             4607       0.205021  \n",
       "19                                              795       0.111996  \n",
       "20                                             1543       0.141013  \n",
       "20                                             2104       0.150402  \n",
       "22                                             2096       0.119801  \n",
       "23                                             1693       0.135599  \n",
       "24                                             4212       0.134017  \n",
       "25                                              937       0.114402  \n",
       "25                                             3802       0.128401  \n",
       "25                                             2528       0.124036  \n",
       "28                                             1192       0.131802  \n",
       "28                                             3581       0.134407  \n",
       "30                                              538       0.132820  \n",
       "31                                              655       0.122206  \n",
       "31                                             1446       0.144276  \n",
       "33                                             1259       0.156055  \n",
       "34                                              471       0.144620  \n",
       "35                                             1079       0.108406  \n",
       "36                                             1482       0.103800  \n",
       "37                                             1211       0.111214  \n",
       "38                                             4335       0.121806  \n",
       "39                                             2438       0.109799  \n",
       "40                                              490       0.101001  \n",
       "41                                             1050       0.100802  \n",
       "42                                              371       0.150997  \n",
       "43                                             1446       0.114610  \n",
       "44                                             3037       0.102022  \n",
       "45                                             1542       0.096001  \n",
       "46                                             1233       0.095207  \n",
       "47                                              196       0.130598  \n",
       "48                                             2150       0.095229  \n",
       "49                                             2341       0.093795  \n",
       "50                                              421       0.090798  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best hyperparameter values: \", random_search.best_params_)\n",
    "print(\"Best score: %0.3f\" % (random_search.best_score_))\n",
    "\n",
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\n",
    "        \"mean_train_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"param_logisticregression__C\",\n",
    "        \"param_countvectorizer__max_features\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg feats</th>\n",
       "      <th>Neg weights</th>\n",
       "      <th>Pos feats</th>\n",
       "      <th>Pos weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thats</td>\n",
       "      <td>-1.609052</td>\n",
       "      <td>flavorful</td>\n",
       "      <td>0.648075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-1.474498</td>\n",
       "      <td>more</td>\n",
       "      <td>0.663106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered</td>\n",
       "      <td>-1.261018</td>\n",
       "      <td>tried</td>\n",
       "      <td>0.672982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>never</td>\n",
       "      <td>-1.239542</td>\n",
       "      <td>end</td>\n",
       "      <td>0.688098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>-1.211926</td>\n",
       "      <td>yam</td>\n",
       "      <td>0.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>there</td>\n",
       "      <td>-1.102574</td>\n",
       "      <td>amazing</td>\n",
       "      <td>0.702996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>off</td>\n",
       "      <td>-1.022058</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.703865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>not</td>\n",
       "      <td>-0.989468</td>\n",
       "      <td>favourite</td>\n",
       "      <td>0.719984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>-0.977897</td>\n",
       "      <td>worth</td>\n",
       "      <td>0.721632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dish</td>\n",
       "      <td>-0.971393</td>\n",
       "      <td>friendly</td>\n",
       "      <td>0.728340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>two</td>\n",
       "      <td>-0.970118</td>\n",
       "      <td>something</td>\n",
       "      <td>0.786062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nothing</td>\n",
       "      <td>-0.927127</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>0.820627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>until</td>\n",
       "      <td>-0.903792</td>\n",
       "      <td>right</td>\n",
       "      <td>0.821487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roll</td>\n",
       "      <td>-0.825853</td>\n",
       "      <td>location</td>\n",
       "      <td>0.822492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>told</td>\n",
       "      <td>-0.825424</td>\n",
       "      <td>good</td>\n",
       "      <td>0.852516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eating</td>\n",
       "      <td>-0.823108</td>\n",
       "      <td>menu</td>\n",
       "      <td>0.881738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>think</td>\n",
       "      <td>-0.778895</td>\n",
       "      <td>great</td>\n",
       "      <td>0.886293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>have</td>\n",
       "      <td>-0.774806</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>1.021068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>business</td>\n",
       "      <td>-0.756703</td>\n",
       "      <td>love</td>\n",
       "      <td>1.059732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cold</td>\n",
       "      <td>-0.750567</td>\n",
       "      <td>delicious</td>\n",
       "      <td>1.195754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Neg feats  Neg weights  Pos feats  Pos weights\n",
       "0          thats    -1.609052  flavorful     0.648075\n",
       "1   disappointed    -1.474498       more     0.663106\n",
       "2        ordered    -1.261018      tried     0.672982\n",
       "3          never    -1.239542        end     0.688098\n",
       "4        kitchen    -1.211926        yam     0.701833\n",
       "5          there    -1.102574    amazing     0.702996\n",
       "6            off    -1.022058       nice     0.703865\n",
       "7            not    -0.989468  favourite     0.719984\n",
       "8           like    -0.977897      worth     0.721632\n",
       "9           dish    -0.971393   friendly     0.728340\n",
       "10           two    -0.970118  something     0.786062\n",
       "11       nothing    -0.927127   sandwich     0.820627\n",
       "12         until    -0.903792      right     0.821487\n",
       "13          roll    -0.825853   location     0.822492\n",
       "14          told    -0.825424       good     0.852516\n",
       "15        eating    -0.823108       menu     0.881738\n",
       "16         think    -0.778895      great     0.886293\n",
       "17          have    -0.774806  vancouver     1.021068\n",
       "18      business    -0.756703       love     1.059732\n",
       "19          cold    -0.750567  delicious     1.195754"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = best_estimator[\n",
    "    \"countvectorizer\"\n",
    "].get_feature_names()  # Get features (words in our case)\n",
    "\n",
    "weights = best_estimator[\n",
    "    \"logisticregression\"\n",
    "].coef_.flatten()  # Get feature coefficients\n",
    "\n",
    "inds = np.argsort(\n",
    "    best_estimator[\"logisticregression\"].coef_.flatten()\n",
    ")  # Sort the coefficients in descending order\n",
    "\n",
    "\n",
    "negative_words = [\n",
    "    vocab[index] for index in inds[:20]\n",
    "]  # pick the first 20 as most informative features for negative reviews\n",
    "\n",
    "positive_words = [\n",
    "    vocab[index] for index in inds[-20:]\n",
    "]  # pick the last 20 features as most informative features for positive reviews\n",
    "\n",
    "neg_words_weights = [(weights[index]) for index in inds[:20]]\n",
    "pos_words_weights = [(weights[index]) for index in inds[-20:]]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Neg feats\": negative_words,\n",
    "        \"Neg weights\": neg_words_weights,\n",
    "        \"Pos feats\": positive_words,\n",
    "        \"Pos weights\": pos_words_weights,\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search best model score: 0.868\n",
      "Train score on the full train set: 1.000\n",
      "Test score on the full test set: 0.857\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(\n",
    "    X_train, y_train\n",
    ")  # Not necessary, as by default `refit=True` in `RandomizedSearchCV`. But OK for the purpose of this lab.\n",
    "print(\"Grid Search best model score: %0.3f\" % (random_search.best_score_))\n",
    "print(\"Train score on the full train set: %0.3f\" % (best_model.score(X_train, y_train)))\n",
    "print(\"Test score on the full test set: %0.3f\" % (best_model.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive review where the prob of being positive is 1.000:\n",
      "I absolutely love Chau I cant believe that for years I held off trying it because I was under the false belief that I wouldnt feel fully satisfied with it being vegan I finally tried it one evening with a vegan friend and boy was I wrong The moment the golden temple broth touched my lips I was hooked Ive been coming here regularly ever since Even my meat-loving boyfriend loves it Im so obsessed with the golden-temple soup that I cant not order it every single time My favourite way to have it is with the quinoa which sounds like its going to be too healthy tasting but it just compliments the soup so well The texture of the quinoa is so nice in the soup and it doesnt really absorb the broth too much I also like to get extra veggies between my boyfriend and I we get one order of extra regular veggies broccoli cauliflower carrot and one extra order of yams The extra veggies makes it all the more hearty and I always have leftovers Even though I always get the golden temple Ive tried lots of other things too Everything so far has been delicious Ive tried the diving for pearls soup  which is really tasty the fresh rolls the tempeh one is my absolute favourite the baisou chips must get the coconut shake so yummy must try and the peanut bar you absolutely must get this The ice cream is also really yummy my favourite is the green goodness I dont usually like vegan ice cream but this is so delish Chau is a great place for a quick casual healthy bite for vegans and non-vegans a like The service is always friendly and prompt and the food is always delicious and consistent It also a great place for takeout which is especially important in these times I find in a lot of other restaurants the food either doesnt take out well or you end up getting screwed on the portion size or preparation So Its really nice to find a restaurant where you know you are going to be equally satisfied when choosing takeout and never have to worry about feeling ripped off Im sure Ill be back again next week for my favourite golden temple soup\n"
     ]
    }
   ],
   "source": [
    "most_pos_prob = np.max(best_model.predict_proba(X_test)[:, 1])\n",
    "most_pos_ind = np.argmax(best_model.predict_proba(X_test)[:, 1])\n",
    "print(\n",
    "    \"Most positive review where the prob of being positive is %0.3f:\\n%s\"\n",
    "    % (most_pos_prob, X_test.iloc[most_pos_ind])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative review where the prob of being positive is 0.000:\n",
      "Visit the Arbor if you feel like getting yelled at by a server My spouse and I attended the Arbor to purchase a gift card or gift certificate for a friend We like the food at the Arbor and because we live nearby we find ourselves there once a month or so often brining along friends or family Today when we approached the counter I started to request information about a gift card or gift certificate I began to say Hi would it be possible to before I was rudely cut off by the man at the desk He raised his voice interrupting me mid-sentence to say Ill be with you in a minute Needless to say my spouse and I were put off enough that we left and will not be returning With his condescending and unfriendly behavior the staffperson at the front counter not only lost our business tonight in terms of the gift card we hoped to buy but our business in the future and the business of our friends for whom we were buying the gift card It wouldnt have bothered me to wait a few minutes while he finished whatever he was doing he was not serving another customer or on the phone when I approached the counter Unfortunately he didnt even have the patience to let me finish my sentence The Arbor is becoming widely known for good food and bad service This is not the first time weve had an experience like this at the Arbor and we intend to take our business somewhere that were treated with a modicum of respect I tried to post on their Instagram account about my experience and they blocked me Worst service Ive ever experienced in Vancouver Do yourself a favor and stay home\n"
     ]
    }
   ],
   "source": [
    "most_neg_prob = np.min(best_model.predict_proba(X_test)[:, 1])\n",
    "most_neg_ind = np.argmin(best_model.predict_proba(X_test)[:, 1])\n",
    "print(\n",
    "    \"Most negative review where the prob of being positive is %0.3f:\\n%s\"\n",
    "    % (most_neg_prob, X_test.iloc[most_neg_ind])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
